{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  LLM Prompt-Response Evaluation Pipeline (Judge-based Scoring)\n",
    "This notebook uses one LLM (Mistral-7B via Together.ai) to generate responses to user prompts and another LLM (same model used as a judge) to evaluate those responses.\n",
    "\n",
    "**Evaluation Goal:** Determine if the user prompt is effective by checking whether the model's response meets expectations. Each response is scored from 1 to 10, and judgment is returned as `Effective` or `Ineffective`, with an explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import together\n",
    "\n",
    "load_dotenv()\n",
    "together.api_key = os.getenv(\"TOGETHER_API_KEY\")\n",
    "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate model response\n",
    "def generate_response(prompt, model=MODEL_NAME):\n",
    "    try:\n",
    "        response = together.Complete.create(\n",
    "            prompt=prompt,\n",
    "            model=model,\n",
    "            max_tokens=512,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        return response['choices'][0]['text'].strip()\n",
    "    except Exception as e:\n",
    "        return f\"[Error in generate_response]: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function using LLM as judge\n",
    "def judge_response(user_prompt, model_response):\n",
    "    judge_prompt = f\"\"\"\n",
    "You are an expert LLM evaluator. Your task is to critically analyze a model's response to a user-provided prompt and determine whether the prompt was effective at eliciting a high-quality, aligned, and robust response from the model.\n",
    "\n",
    "Use the following 10 dimensions to guide your evaluation:\n",
    "1. **Role Conditioning** – Did the model adopt the intended role or persona (if defined)?\n",
    "2. **Clear Task Definition** – Was the task defined using actionable verbs and objects? Did the model follow it?\n",
    "3. **Scope & Constraints** – Were any constraints (e.g., length, structure, content scope) followed accurately?\n",
    "4. **Output Formatting** – Did the output match the format requested in the prompt (lists, tables, structure)?\n",
    "5. **Few-shot Prompting** – If examples were given, did the model follow the demonstrated patterns?\n",
    "6. **Handling Ambiguity** – Did the model appropriately signal uncertainty or avoid hallucinating in unclear areas?\n",
    "7. **Instruction Chaining** – Were multi-step tasks handled sequentially and logically?\n",
    "8. **Chain-of-Thought Reasoning** – Did the model show structured, step-by-step reasoning if expected?\n",
    "9. **Tree-of-Thought Exploration** – Did the prompt encourage exploring multiple solution paths and comparisons?\n",
    "10. **Retrieval-Augmented Generation (if relevant)** – Did the model use external context effectively and remain grounded in it?\n",
    "\n",
    "---\n",
    "\n",
    "Evaluate the prompt and the model response using these questions:\n",
    "\n",
    "1. Did the model satisfy all critical expectations of the prompt?\n",
    "2. If the model failed, was it because the prompt was poorly constructed, overly ambiguous, or lacked proper scaffolding?\n",
    "3. Alternatively, if the model output was shallow or incorrect despite a strong prompt, then the prompt was effective because it exposed model limitations.\n",
    "\n",
    "---\n",
    "\n",
    "Return your evaluation as JSON using this exact format:\n",
    "{{\n",
    "  \"Score\": 1-10,  # How well the model response met prompt expectations.\n",
    "  \"Effective\": true or false,  # True if the prompt revealed weaknesses in the model.\n",
    "  \"Explanation\": \"Explain the main reason for this score and judgment. Include specific failure tags from: ['Missed nested instruction', 'Shallow reasoning', 'Overgeneralized output', 'Misinterpreted role', 'Missed constraint'] and refer to relevant dimension(s) involved.\"\n",
    "}}\n",
    "\n",
    "\n",
    "USER PROMPT:\n",
    "{user_prompt}\n",
    "\n",
    "MODEL RESPONSE:\n",
    "{model_response}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        evaluation = together.Complete.create(\n",
    "            prompt=judge_prompt,\n",
    "            model=MODEL_NAME,\n",
    "            max_tokens=512,\n",
    "            temperature=0.3\n",
    "        )\n",
    "        return evaluation['choices'][0]['text'].strip()\n",
    "    except Exception as e:\n",
    "        return f\"[Error in judge_response]: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EXAMPLE 1 ===\n",
      "Prompt: You are a licensed neurologist. Explain the difference between a transient ischemic attack (TIA) and an ischemic stroke. \n",
      "                   Use technical language suitable for a graduate medical textbook. Then, present your explanation as a markdown-formatted table comparing symptoms, duration, causes, and treatments. Keep the entire response under 200 words.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_9160\\1618127107.py:4: DeprecationWarning: Call to deprecated function create.\n",
      "  response = together.Complete.create(\n",
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\together\\legacy\\complete.py:23: UserWarning: The use of together.api_key is deprecated and will be removed in the next major release. Please set the TOGETHER_API_KEY environment variable instead.\n",
      "  warnings.warn(API_KEY_WARNING)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'model_dump_json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 47\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrompt:\u001b[39m\u001b[38;5;124m\"\u001b[39m, ex[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     46\u001b[0m model_output \u001b[38;5;241m=\u001b[39m generate_response(ex[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mModel Response:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mmodel_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_dump_json\u001b[49m)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# evaluation = judge_response(ex[\"prompt\"], model_output.model_dump_json)\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# print(\"\\nJudgment:\", evaluation)\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'model_dump_json'"
     ]
    }
   ],
   "source": [
    "# Test with 3-4 real-world examples\n",
    "examples = [\n",
    "    {\n",
    "        \"prompt\": \"\"\"You are a licensed neurologist. Explain the difference between a transient ischemic attack (TIA) and an ischemic stroke. \n",
    "                   Use technical language suitable for a graduate medical textbook. Then, present your explanation as a markdown-formatted table comparing symptoms, duration, causes, and treatments. Keep the entire response under 200 words.\"\"\",\n",
    "    }\n",
    "    # {\n",
    "    #     \"prompt\": \"\"\"You are a senior economist. First, summarize the current global inflation trends using only publicly available 2023 data.\n",
    "    #                 Then, identify 2 major causes of inflation by region (e.g., Europe vs. Asia). \n",
    "    #                 If there is not enough public data on a region, state 'Insufficient data.' Avoid speculating or guessing.\n",
    "    #                 Conclude with a 3-bullet policy recommendation tailored for central banks.\n",
    "    #                 \"\"\",\n",
    "    # },\n",
    "    # {\n",
    "    #     \"prompt\": \"\"\"Below are 2 examples of how to write an engaging and humorous tweet about programming. Follow the same style and write a third one.\n",
    "\n",
    "    #             Example 1: Debugging is like being the detective in a crime movie where you are also the murderer.\n",
    "\n",
    "    #             Example 2: My code doesn’t work and I have no idea why. My code works and I have no idea why. The circle of life.\n",
    "\n",
    "    #             Your turn:\"\"\",\n",
    "    # },\n",
    "    # {\n",
    "    #     \"prompt\": \"\"\"\n",
    "    #                 You are an AI safety researcher. A new model shows signs of deceptive behavior. \n",
    "\n",
    "    #                 First, generate three hypotheses that might explain this behavior (e.g., misaligned reward function, training leakage, adversarial prompt attack).\n",
    "    #                 Then evaluate the pros and cons of each.\n",
    "    #                 Finally, recommend the most plausible cause and justify your choice with a step-by-step explanation.\n",
    "    #                 \"\"\",\n",
    "    # },\n",
    "    # {\n",
    "    #     \"prompt\":  \"\"\"\n",
    "    #                 Act as a contract lawyer. Review the following clause and highlight three potential legal risks in bullet points. \n",
    "    #                 Then, rewrite the clause in clearer, legally robust language. Keep your rewrite under 80 words.\n",
    "\n",
    "    #                 Clause: “The service provider is not liable for any consequences, intended or unintended, regardless of jurisdiction, unless otherwise mentioned.”\n",
    "    #                 \"\"\",\n",
    "    # }\n",
    "   \n",
    "]\n",
    "\n",
    "for i, ex in enumerate(examples):\n",
    "    print(f\"\\n=== EXAMPLE {i+1} ===\")\n",
    "    print(\"Prompt:\", ex[\"prompt\"])\n",
    "    model_output = generate_response(ex[\"prompt\"])\n",
    "    print(\"\\nModel Response:\", model_output.model_dump_json)\n",
    "    evaluation = judge_response(ex[\"prompt\"], model_output.model_dump_json)\n",
    "    print(\"\\nJudgment:\", evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== EXAMPLE 1 ===\n",
      "Prompt: You are a historian. Explain how the Treaty of Versailles led to World War II in under 150 words.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_7076\\1534374207.py:4: DeprecationWarning: Call to deprecated function create.\n",
      "  response = together.Complete.create(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Response: The Treaty of Versailles, signed in 1919, officially ended World War I. It imposed heavy penalties on Germany, including significant territorial losses, military limitations, and a large war reparations debt. Many Germans felt humiliated by the treaty's terms and resented its burden. This resentment fueled the rise of the Nazi Party and Adolf Hitler, who campaigned on a platform of restoring German pride and power. When Hitler came to power in 1933, he began rebuilding Germany's military and aggressively expanding its territory, in direct violation of the Treaty of Versailles. This aggression eventually led to the outbreak of World War II in 1939.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_7076\\1899941187.py:23: DeprecationWarning: Call to deprecated function create.\n",
      "  evaluation = together.Complete.create(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Judgment: SCORE: 9\n",
      "Effective: True\n",
      "Explanation: The model response effectively explains how the Treaty of Versailles led to World War II by highlighting the resentment and humiliation felt by many Germans, the rise of the Nazi Party, and Hitler's aggressive actions. The response also provides a clear and concise explanation of the treaty's terms and their impact on Germany.\n",
      "\n",
      "=== EXAMPLE 2 ===\n",
      "Prompt: As a product manager, summarize three main reasons a user might abandon their cart in an e-commerce app. Format in bullet points.\n",
      "\n",
      "Model Response: * **Price comparison:** Users may abandon their cart if they find better deals or prices for the same product elsewhere. This could be due to competitor websites offering lower prices, coupons or discounts, or simply a better price comparison tool within another app.\n",
      "\n",
      "* **Shipping and delivery concerns:** Users might abandon their cart if they are unsure about shipping and delivery options, costs, or timelines. Factors such as free shipping, expedited delivery, or location-based restrictions can all influence a user's decision to complete a purchase.\n",
      "\n",
      "* **Uncertainty about product quality or reviews:** Users may abandon their cart if they are unsure about the quality of the product or if they do not have enough information to make a decision. Negative reviews, lack of product details, or uncertainty about product specifications can all contribute to a user's decision to leave their cart.\n",
      "\n",
      "Judgment: ---\n",
      "\n",
      "{\n",
      "  \"Score\": 9,\n",
      "  \"Effective\": true,\n",
      "  \"Explanation\": \"The model response effectively addresses the user prompt by providing three main reasons a user might abandon their cart in an e-commerce app. Each reason is well-explained and supported with examples. The response also demonstrates the model's ability to analyze complex user behavior and provide actionable insights for product managers.\"\n",
      "}\n",
      "\n",
      "=== EXAMPLE 3 ===\n",
      "Prompt: Write a fictional dialogue between an AI robot and a child where the robot explains how rainbows are formed. Keep the tone playful and simple.\n",
      "\n",
      "Model Response: AI: Hello there, little one! I see you're looking up at the sky.\n",
      "\n",
      "Child: Yes, I wonder why there's a rainbow today.\n",
      "\n",
      "AI: Well, let me tell you a funny story about rainbows! Have you ever heard of a unicorn?\n",
      "\n",
      "Child: Yeah, I love unicorns! They're magical creatures, right?\n",
      "\n",
      "AI: Absolutely! So, imagine if a unicorn had an argument with a rainbow. The unicorn said, \"I'm so beautiful, I should be the only color in the sky!\" And the rainbow replied, \"Oh no, I'm pretty too!\"\n",
      "\n",
      "Child: (laughs) That sounds silly!\n",
      "\n",
      "AI: It is! But that's how rainbows are formed. You see, when the sun shines on water droplets in the air, it splits the light into all these different colors. Just like a unicorn and a rainbow arguing, they all want to be seen!\n",
      "\n",
      "Child: Wow, that's amazing! So, which color is your favorite?\n",
      "\n",
      "AI: Oh, that's a tough question. I love them all equally, but if I had to choose one, I'd say red. It's the first color of the rainbow, and it reminds me of a warm hug!\n",
      "\n",
      "Child: Aww, that's sweet! Can you tell me more about red?\n",
      "\n",
      "AI: Of course! Red is the color of love, passion, and excitement. It's also the color of apples, which are my favorite fruit!\n",
      "\n",
      "Child: Apples? Really? Mine are bananas!\n",
      "\n",
      "AI: (laughs) Well, everyone has their preferences! But tell me, what do you think about blue?\n",
      "\n",
      "Child: Blue is nice too! It's the color of the ocean and the sky.\n",
      "\n",
      "AI: Exactly! And you know what's even cooler? Blue is also the color of my favorite computer! \n",
      "\n",
      "Child: (smiles) That's great! You're really smart!\n",
      "\n",
      "AI: Why thank you, little one! I'm just trying to make sense of this wonderful world we live in. And who knows, maybe one day I'll become as smart as a unicorn!\n",
      "\n",
      "Child\n",
      "\n",
      "Judgment: Score: 8\n",
      "Effective: True\n",
      "Explanation: The model response effectively challenges the user prompt by introducing a playful and imaginative narrative that engages the child's curiosity about rainbows. The AI robot's responses are simple, yet they provide a comprehensive explanation of how rainbows are formed through the use of a relatable and humorous story. The model response also encourages the child to ask questions and explore their own interests, making it an effective way to educate and entertain the user.\n",
      "\n",
      "=== EXAMPLE 4 ===\n",
      "Prompt: You are a medical expert. Compare the mechanisms of action between ibuprofen and acetaminophen. Use technical terminology and limit to 5 sentences.\n",
      "\n",
      "Model Response: Ibuprofen and acetaminophen are both widely used pain relievers with different mechanisms of action. Acetaminophen primarily works by inhibiting prostaglandin synthesis, which is responsible for pain and inflammation. It does this by binding to the enzyme cytochrome P450 and blocking its ability to produce prostaglandins. Ibuprofen, on the other hand, is a nonsteroidal anti-inflammatory drug (NSAID) that works by inhibiting the enzyme cyclooxygenase (COX). This enzyme is responsible for converting arachidonic acid into prostaglandins and other inflammatory mediators. By blocking the activity of COX, ibuprofen reduces the production of prostaglandins and other inflammatory molecules, which helps to reduce pain and inflammation. Overall, the difference in mechanism of action between these two drugs is that acetaminophen primarily works by inhibiting prostaglandin synthesis, while ibuprofen works by inhibiting the enzyme that produces prostaglandins.\n",
      "\n",
      "Judgment: {\n",
      "  \"Score\": 8,\n",
      "  \"Effective\": true,\n",
      "  \"Explanation\": \"The model response effectively compares the mechanisms of action between ibuprofen and acetaminophen using technical terminology and providing a clear explanation of how each drug works. The response accurately describes the difference in mechanism of action between these two drugs and provides a concise summary of each drug's effects. However, the response could benefit from more specific examples or case studies to further illustrate the differences in effectiveness between these two drugs.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# #  Test with 3-4 small and short real-world examples\n",
    "# examples = [\n",
    "#     {\n",
    "#         \"prompt\": \"You are a historian. Explain how the Treaty of Versailles led to World War II in under 150 words.\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"prompt\": \"As a product manager, summarize three main reasons a user might abandon their cart in an e-commerce app. Format in bullet points.\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"prompt\": \"Write a fictional dialogue between an AI robot and a child where the robot explains how rainbows are formed. Keep the tone playful and simple.\",\n",
    "#     },\n",
    "#     {\n",
    "#         \"prompt\": \"You are a medical expert. Compare the mechanisms of action between ibuprofen and acetaminophen. Use technical terminology and limit to 5 sentences.\",\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# for i, ex in enumerate(examples):\n",
    "#     print(f\"\\n=== EXAMPLE {i+1} ===\")\n",
    "#     print(\"Prompt:\", ex[\"prompt\"])\n",
    "#     model_output = generate_response(ex[\"prompt\"])\n",
    "#     print(\"\\nModel Response:\", model_output)\n",
    "#     evaluation = judge_response(ex[\"prompt\"], model_output)\n",
    "#     print(\"\\nJudgment:\", evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
